shiny::runApp('C:/Users/singe/Downloads')
install.packages("shinydashboard")
runApp('C:/Users/singe/Downloads')
install.packages("ggiraph")
runApp('C:/Users/singe/Downloads')
install.packages("ggiraphExtra")
runApp('C:/Users/singe/Downloads')
install.packages("rgl")
runApp('C:/Users/singe/Downloads')
install.packages("tree")
runApp('C:/Users/singe/Downloads')
library(shiny)
runGitHub("ST-558-Final-Project", "kylebeard56", ref = "master")
?randomForest
??randomForest
library(caret)
?randomForest
sample(1:20)
sample(1:20, size=.8)
sample(1:20, size=20*.8)
heartData <- read.csv("heart_failure_clinical_records_dataset.csv")
str(heartData)
library(shiny); runApp('C:/Users/singe/Downloads/original.R')
runGitHub("ST-558-Final-Project", "kylebeard56", ref = "master")
runApp('C:/Users/singe/Downloads')
shinyApp(ui = ui, server = server)
ls
ls()
runApp()
runApp()
View(heartData)
runApp()
runApp()
runApp()
runApp()
?checkboxInput
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
?box
runApp()
?train
heartData <- read.csv("heart_failure_clinical_records_dataset.csv")
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("age~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
log_mod = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
metric="ROC",
na.action = na.omit
)
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
ogisticFormula<-as.formula("age~.")
logisticFormula<-as.formula("age~.")
log_mod = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
metric="ROC",
na.action = na.omit
)
summary(heartData$DEATH_EVENT)
response<-heartdata%>%mutate(DEATH_EVENT=as.factor(case_when(
DEATH_EVENT==0|~"death",
DEATH_EVENT==1 ~ "live")))
response<-heartData%>%mutate(DEATH_EVENT=as.factor(case_when(
DEATH_EVENT==0|~"death",
DEATH_EVENT==1 ~ "live")))
attributes(healthData)
attributes(heartData)
summary(heartData)
response<-heartData%>%mutate(DEATH_EVENT=as.factor(case_when(
DEATH_EVENT=='0'|~"death",
DEATH_EVENT=='1' ~ "live")))
response<-heartData%>%mutate(as.factor(as.character(DEATH_EVENT)))
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("(as.factor(as.character(HEALTH_EVENT)))~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
log_mod = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
metric="ROC",
na.action = na.omit
)
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("(as.factor(as.character(DEATH_EVENT)))~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
log_mod = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
metric="ROC",
na.action = na.omit
)
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
data$DEATH_EVENT <- factor(data$DEATH_EVENT, levels = c(0, 1), labels = c("ND", "D"))
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
data$DEATH_EVENT <- factor(data$DEATH_EVENT, levels = c(0, 1), labels = c("ND", "D"))
factor(data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
data$DEATH_EVENT <- factor(data$DEATH_EVENT, levels = c(0, 1), labels = c("ND", "D"))
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
data$DEATH_EVENT <- factor(data$DEATH_EVENT, levels = c(0, 1), labels = c("ND", "D"))
factor(heartData$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
modeling_data$DEATH_EVENT<-factor(modeling_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
modeling_data$DEATH_EVENT<-factor(modeling_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
test_data$DEATH_EVENT<-factor(test_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
data$DEATH_EVENT <- factor(data$DEATH_EVENT, levels = c(0, 1), labels = c("ND", "D"))
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
modeling_data$DEATH_EVENT<-factor(modeling_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
test_data$DEATH_EVENT<-factor(test_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("DEATH_EVENT~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
log_mod = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
metric="ROC",
na.action = na.omit
)
summary (log_mod)
str(log_mod)
log_mod$finalModel
log_mod$results
rfFormula <- logisticFormula
set.seed(102)
rfFit <- train(form=rfFormula,
data=modeling_data,
method="rf",
trControl=mycontrol,
tuneGrid=data.frame(mtry=1:4))
rfFit$results
rfFit$bestTune
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
modeling_data$DEATH_EVENT<-factor(modeling_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
test_data$DEATH_EVENT<-factor(test_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
#summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("DEATH_EVENT~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
metric="ROC",
na.action = na.omit
)
#Random Forest
rfFormula <- logisticFormula
set.seed(102)
rfFit <- train(form=rfFormula,
data=modeling_data,
method="rf",
trControl=mycontrol,
tuneGrid=data.frame(mtry=1:4))
rfFit$results
rfFit$bestTune
log_mod
logFit
summary(logFit)
View(heartData)
?treebag
ntrees <- 200
btFit <- train(
form=logisticFormula,
data = modeling_data,
method = "treebag",  # Use "treebag" for bagging
trControl = mycontrol,
ntrees = ntrees
)
btFit
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
modeling_data$DEATH_EVENT<-factor(modeling_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
test_data$DEATH_EVENT<-factor(test_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
#summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("DEATH_EVENT~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
summaryFunction = twoClassSummary,
na.action = na.omit
)
library(caret)
library(tidyverse)
# Create an index vector for stratified sampling
set.seed(101)
index <- createDataPartition(heartData$DEATH_EVENT, p = 0.8, list = FALSE)
# Split the data into 80% and 20% samples
modeling_data <- heartData[index, ]
test_data <- heartData[-index, ]
modeling_data$DEATH_EVENT<-factor(modeling_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
test_data$DEATH_EVENT<-factor(test_data$DEATH_EVENT, levels=c(0,1), labels=c("ND", "D"))
#Logistic regression
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE)
logisticFormula<-as.formula("DEATH_EVENT~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
na.action = na.omit
)
#Random Forest
rfFormula <- logisticFormula
set.seed(102)
rfFit <- train(form=rfFormula,
data=modeling_data,
method="rf",
trControl=mycontrol,
tuneGrid=data.frame(mtry=1:4))
rfFit$results
rfFit$bestTune
#Bagged trees
ntrees <- 200
btFit <- train(
form=logisticFormula,
data = modeling_data,
method = "treebag",  # Use "treebag" for bagging
trControl = mycontrol,
ntrees = ntrees
)
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
na.action = na.omit
)
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
na.action = pass
)
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
na.action = na.pass
)
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE,
metric="Accuracy")
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE
)
logisticFormula<-as.formula("DEATH_EVENT~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
metric="Accuracy",
family = "binomial",
na.action = na.omit
)
mycontrol<-trainControl(method = "cv",
number = 10,
summaryFunction = twoClassSummary,
savePredictions = 'all',
classProbs = TRUE
)
logisticFormula<-as.formula("DEATH_EVENT~.")
#set seed for reproducibility
set.seed(101)
# Run the model.  Will use the out-of-bag samples to make predictions.
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
method = "glm",
family = "binomial",
na.action = na.omit
)
?predict
pred<-predict(logFit, newdata=test_data)
postResample(pred, test_data$DEATH_EVENT)
pred<-predict(rfFit, newdata=test_data)
postResample(pred, test_data$DEATH_EVENT)
pred<-predict(btFit, newdata=test_data)
postResample(pred, test_data$DEATH_EVENT)
varImp(rfFit)
rfFit
logFit = train(
form = logisticFormula,
data = modeling_data,
trControl= mycontrol,
preProcess=c("center","scale"),
method = "glm",
family = "binomial",
na.action = na.omit
)
pred<-predict(logFit, newdata=test_data)
postResample(pred, test_data$DEATH_EVENT)
train_predictions <- logFit$pred$obs     # Extract actual training data target values
train_predicted <- logFit$pred$pred      # Extract predicted training data target values
mse_training <- mean((train_predictions - train_predicted) ^ 2)  # Calculate MSE
train_predictions
train_predicted
# Step 4: Calculate accuracy of the training data using the confusion matrix
conf_matrix <- confusionMatrix(data = factor(train_predicted, levels = levels(train_predictions)),
reference = factor(train_predictions, levels = levels(train_predictions)))
# Extract accuracy from the confusion matrix
accuracy_training <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy of the training data:", accuracy_training))
observed <- logFit$pred$obs     # Extract actual training data target values
train_predicted <- logFit$pred$pred      # Extract predicted training data target values
# Calculate accuracy of the training data using the confusion matrix
conf_matrix <- confusionMatrix(data = factor(train_predicted, levels = levels(train_predictions)),
reference = factor(observed, levels = levels(observed)))
# Extract accuracy from the confusion matrix
accuracy_training <- conf_matrix$overall["Accuracy"]
print(paste("Accuracy of the training data:", accuracy_training))
conf_matrix
runApp()
?tabBox
runApp()
?DT::renderDT
runApp()
?dataTableOutput
runApp()
runApp()
runApp()
